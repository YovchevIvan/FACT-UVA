{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACT-UVA: Man is to Programmer as Woman is to Homemaker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "Debiaswe: https://github.com/tolga-b/debiaswe\n",
    "Lipstick: https://github.com/gonenhila/gender_bias_lipstick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the GoogleNews word2vec embeddings:\n",
    "Download it directly from the official [website](https://code.google.com/archive/p/word2vec/) or clone [this github repo](https://github.com/mmihaltz/word2vec-GoogleNews-vectors). Place the downloaded **.bin** file in the embeddings folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the Glove embeddings:\n",
    "Go to the official [website](https://nlp.stanford.edu/projects/glove/). Download **glove.840B.300d.zip**. Place the downloaded **.txt** file in the embeddings folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec\n",
    "\n",
    "The code block bellow executes the main debias function using the word2vec Google News embeddings. Additionally, the function takes as arugments several json files with definitional pairs and geneder specific words as described in the original paper. The function outputs two files - **bias_word2vec.bin** and **debiased_word2vec.bin**, which correspond to the embeddings before and after debiasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(bias_o_em='embeddings/bias_word2vec.bin', debias_o_em='embeddings/debiased_word2vec.bin', def_fn='data/definitional_pairs.json', em_limit=50000, eq_fn='data/equalize_pairs.json', g_words_fn='data/gender_specific_full.json', i_em='embeddings/GoogleNews-vectors-negative300.bin', o_ext='bin')\n",
      "*** Reading data from embeddings/GoogleNews-vectors-negative300.bin\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "Number of words:  26391\n",
      "Saving biased vectors to file...\n",
      "Debiasing...\n",
      "Saving to file...\n",
      "\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debias word2vec embeddings\n",
    "!python3 code/main.py --debias_o_em=embeddings/debiased_word2vec.bin --i_em=embeddings/GoogleNews-vectors-negative300.bin --bias_o_em=embeddings/bias_word2vec.bin --def_fn=data/definitional_pairs.json --g_words_fn=data/gender_specific_full.json --eq_fn=data/equalize_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove\n",
    "\n",
    "The only difference between the two formats (word2vec and glove) is that the first line of word2vec contains the number of words and the vector size, while glove does no contain said line. In order to simply things and reduce the lenght of the code we can convert one of the two to the other format. This way the code has to supoort only one format. The code block below converts the glove embeddings to the word2vec fromat. Said code block needs to be executed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting number of vectors\n",
      "there are 2196017 lines\n",
      "extracting vector dimension\n",
      "cat: write error: Broken pipe\n",
      "vectors have size 300\n",
      "creating word2vec format file\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# convert glove to word2vec format\n",
    "!code/scripts/gloveToW2V.sh embeddings/glove.840B.300d.txt embeddings/glove.formatted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the glove embeddings to the word2vec format we can rerun the previous experiment this time using the glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debias glove embeddings\n",
    "!python3 code/main.py --debias_o_em=embeddings/debiased_glove.bin --i_em=embeddings/glove.formatted.txt --bias_o_em=embeddings/bias_glove.bin --def_fn=data/definitional_pairs.json --g_words_fn=data/gender_specific_full.json --eq_fn=data/equalize_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
