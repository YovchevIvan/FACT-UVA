{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACT-UVA: Man is to Programmer as Woman is to Homemaker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "Debiaswe: https://github.com/tolga-b/debiaswe\n",
    "Lipstick: https://github.com/gonenhila/gender_bias_lipstick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the GoogleNews word2vec embeddings:\n",
    "Download it directly from the official [website](https://code.google.com/archive/p/word2vec/) or clone [this github repo](https://github.com/mmihaltz/word2vec-GoogleNews-vectors). Place the downloaded **.bin** file in the embeddings folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the Glove embeddings:\n",
    "Go to the official [website](https://nlp.stanford.edu/projects/glove/). Download **glove.840B.300d.zip**. Place the downloaded **.txt** file in the embeddings folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec\n",
    "\n",
    "The code block bellow executes the main debias function using the word2vec Google News embeddings. Additionally, the function takes as arugments several json files with definitional pairs and geneder specific words as described in the original paper. The function outputs two files - **bias_word2vec.bin** and **debiased_word2vec.bin**, which correspond to the embeddings before and after debiasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(bias_o_em='embeddings/bias_word2vec.bin', debias_o_em='embeddings/debiased_word2vec.bin', def_fn='data/definitional_pairs.json', em_limit=50000, eq_fn='data/equalize_pairs.json', g_words_fn='data/gender_specific_full.json', i_em='embeddings/GoogleNews-vectors-negative300.bin', o_ext='bin')\n",
      "*** Reading data from embeddings/GoogleNews-vectors-negative300.bin\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "Number of words:  26391\n",
      "Saving biased vectors to file...\n",
      "Debiasing...\n",
      "Saving to file...\n",
      "\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debias word2vec embeddings\n",
    "!python3 code/main.py --debias_o_em=embeddings/debiased_word2vec.bin --i_em=embeddings/GoogleNews-vectors-negative300.bin --bias_o_em=embeddings/bias_word2vec.bin --def_fn=data/definitional_pairs.json --g_words_fn=data/gender_specific_full.json --eq_fn=data/equalize_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove\n",
    "\n",
    "The only difference between the two formats (word2vec and glove) is that the first line of word2vec contains the number of words and the vector size, while glove does no contain said line. In order to simply things and reduce the lenght of the code we can convert one of the two to the other format. This way the code has to supoort only one format. The code block below converts the glove embeddings to the word2vec fromat. Said code block needs to be executed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting number of vectors\n",
      "there are 2196017 lines\n",
      "extracting vector dimension\n",
      "cat: write error: Broken pipe\n",
      "vectors have size 300\n",
      "creating word2vec format file\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# convert glove to word2vec format\n",
    "!code/scripts/gloveToW2V.sh embeddings/glove.840B.300d.txt embeddings/glove.formatted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the glove embeddings to the word2vec format we can rerun the previous experiment this time using the glove embeddings. The function will generate two files again - **bias_glove.bin** and **debiased_glove.bin** respectfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(bias_o_em='embeddings/bias_glove.bin', debias_o_em='embeddings/debiased_glove.bin', def_fn='data/definitional_pairs.json', em_limit=50000, eq_fn='data/equalize_pairs.json', g_words_fn='data/gender_specific_full.json', i_em='embeddings/glove.formatted.txt', o_ext='bin')\n",
      "*** Reading data from embeddings/glove.formatted.txt\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "Number of words:  23177\n",
      "Saving biased vectors to file...\n",
      "Debiasing...\n",
      "Saving to file...\n",
      "\n",
      "\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debias glove embeddings\n",
    "!python3 code/main.py --debias_o_em=embeddings/debiased_glove.bin --i_em=embeddings/glove.formatted.txt --bias_o_em=embeddings/bias_glove.bin --def_fn=data/definitional_pairs.json --g_words_fn=data/gender_specific_full.json --eq_fn=data/equalize_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark debiased embeddings\n",
    "\n",
    "After generating the 4 embeddings files (both biased and debiased for word2vec and glove) we can run the benchmark tests on them to determine if the removing of the biased led to any deterioration. The results from the benchmarks would also show if the results have been replicated using the glove embeddings. The code block bellow evaluates each of the 4 embeddings on all of the benchmark test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:00:29 INFO:loading projection weights from /mnt/windows_drive_d/Amsterdam University/Year_1/FACT/embeddings/bias_word2vec.bin\n",
      "05:00:29 INFO:Loading #26391 words with 300 dim\n",
      "05:00:30 INFO:Transformed 26391 into 26391 words\n",
      "05:00:30 INFO:Calculating similarity benchmarks\n",
      "05:00:30 WARNING:Missing 41 words. Will replace them with mean vector\n",
      "05:00:30 INFO:Spearman correlation of scores on WS353 0.6488884094043214\n",
      "05:00:30 WARNING:Missing 105 words. Will replace them with mean vector\n",
      "05:00:30 INFO:Spearman correlation of scores on MTurk 0.513563416944097\n",
      "05:00:30 WARNING:Missing 25 words. Will replace them with mean vector\n",
      "05:00:30 INFO:Spearman correlation of scores on WS353S 0.7197011080164891\n",
      "05:00:30 WARNING:Missing 17 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Spearman correlation of scores on SimLex999 0.43510114901981567\n",
      "05:00:31 WARNING:Missing 23 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Spearman correlation of scores on WS353R 0.5805558093795756\n",
      "05:00:31 WARNING:Missing 528 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Spearman correlation of scores on MEN 0.7042259430744064\n",
      "05:00:31 WARNING:Missing 12 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Spearman correlation of scores on RG65 0.6937745222655595\n",
      "05:00:31 WARNING:Missing 1924 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Spearman correlation of scores on RW 0.27659989138184415\n",
      "05:00:31 INFO:Calculating analogy benchmarks\n",
      "05:00:31 WARNING:Missing 29945 words. Will replace them with mean vector\n",
      "05:00:31 INFO:Processing 1/196 batch\n",
      "05:00:32 INFO:Processing 20/196 batch\n",
      "05:00:33 INFO:Processing 39/196 batch\n",
      "05:00:34 INFO:Processing 58/196 batch\n",
      "05:00:35 INFO:Processing 77/196 batch\n",
      "05:00:37 INFO:Processing 96/196 batch\n",
      "05:00:38 INFO:Processing 115/196 batch\n",
      "05:00:39 INFO:Processing 134/196 batch\n",
      "05:00:40 INFO:Processing 153/196 batch\n",
      "05:00:41 INFO:Processing 172/196 batch\n",
      "05:00:42 INFO:Processing 191/196 batch\n",
      "05:00:42 INFO:Analogy prediction accuracy on Google 0.3340667212443717\n",
      "05:00:42 WARNING:Missing 2171 words. Will replace them with mean vector\n",
      "05:00:42 INFO:Processing 1/80 batch\n",
      "05:00:43 INFO:Processing 9/80 batch\n",
      "05:00:43 INFO:Processing 17/80 batch\n",
      "05:00:44 INFO:Processing 25/80 batch\n",
      "05:00:44 INFO:Processing 33/80 batch\n",
      "05:00:45 INFO:Processing 41/80 batch\n",
      "05:00:45 INFO:Processing 49/80 batch\n",
      "05:00:45 INFO:Processing 57/80 batch\n",
      "05:00:46 INFO:Processing 65/80 batch\n",
      "05:00:46 INFO:Processing 73/80 batch\n",
      "05:00:47 INFO:Analogy prediction accuracy on MSR 0.56975\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "05:00:47 INFO:Analogy prediction accuracy on SemEval2012 0.20206204791924776\n",
      "05:00:47 INFO:Calculating categorization benchmarks\n",
      "05:00:47 DEBUG:Purity=0.670 using affinity=euclidean linkage=ward\n",
      "05:00:47 DEBUG:Purity=0.515 using affinity=cosine linkage=average\n",
      "05:00:47 DEBUG:Purity=0.600 using affinity=cosine linkage=complete\n",
      "05:00:47 DEBUG:Purity=0.385 using affinity=euclidean linkage=average\n",
      "05:00:47 DEBUG:Purity=0.600 using affinity=euclidean linkage=complete\n",
      "05:00:48 DEBUG:Purity=0.590 using KMeans\n",
      "05:00:48 INFO:Cluster purity on BLESS 0.67\n",
      "05:00:48 DEBUG:Purity=0.600 using affinity=euclidean linkage=ward\n",
      "05:00:48 DEBUG:Purity=0.444 using affinity=cosine linkage=average\n",
      "05:00:48 DEBUG:Purity=0.644 using affinity=cosine linkage=complete\n",
      "05:00:48 DEBUG:Purity=0.444 using affinity=euclidean linkage=average\n",
      "05:00:48 DEBUG:Purity=0.644 using affinity=euclidean linkage=complete\n",
      "05:00:48 DEBUG:Purity=0.644 using KMeans\n",
      "05:00:48 INFO:Cluster purity on ESSLI_2c 0.6444444444444445\n",
      "05:00:51 DEBUG:Purity=0.236 using affinity=euclidean linkage=ward\n",
      "05:00:55 DEBUG:Purity=0.115 using affinity=cosine linkage=average\n",
      "05:00:58 DEBUG:Purity=0.207 using affinity=cosine linkage=complete\n",
      "05:01:02 DEBUG:Purity=0.071 using affinity=euclidean linkage=average\n",
      "05:01:05 DEBUG:Purity=0.205 using affinity=euclidean linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.212 using KMeans\n",
      "05:01:09 INFO:Cluster purity on Battig 0.23551902121965207\n",
      "05:01:09 DEBUG:Purity=0.557 using affinity=euclidean linkage=ward\n",
      "05:01:09 DEBUG:Purity=0.356 using affinity=cosine linkage=average\n",
      "05:01:09 DEBUG:Purity=0.435 using affinity=cosine linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.164 using affinity=euclidean linkage=average\n",
      "05:01:09 DEBUG:Purity=0.435 using affinity=euclidean linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.405 using KMeans\n",
      "05:01:09 INFO:Cluster purity on AP 0.5572139303482587\n",
      "05:01:09 DEBUG:Purity=0.750 using affinity=euclidean linkage=ward\n",
      "05:01:09 DEBUG:Purity=0.800 using affinity=cosine linkage=average\n",
      "05:01:09 DEBUG:Purity=0.450 using affinity=cosine linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.800 using affinity=euclidean linkage=average\n",
      "05:01:09 DEBUG:Purity=0.450 using affinity=euclidean linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.750 using KMeans\n",
      "05:01:09 INFO:Cluster purity on ESSLI_2b 0.8\n",
      "05:01:09 DEBUG:Purity=0.727 using affinity=euclidean linkage=ward\n",
      "05:01:09 DEBUG:Purity=0.727 using affinity=cosine linkage=average\n",
      "05:01:09 DEBUG:Purity=0.682 using affinity=cosine linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.727 using affinity=euclidean linkage=average\n",
      "05:01:09 DEBUG:Purity=0.705 using affinity=euclidean linkage=complete\n",
      "05:01:09 DEBUG:Purity=0.773 using KMeans\n",
      "05:01:09 INFO:Cluster purity on ESSLI_1a 0.7727272727272727\n",
      "05:01:09 INFO:Saving results...\n",
      "         AP  BLESS    Battig      ...          Google      MSR  SemEval2012_2\n",
      "0  0.557214   0.67  0.235519      ...        0.334067  0.56975       0.202062\n",
      "\n",
      "[1 rows x 17 columns]\n",
      "05:01:10 INFO:loading projection weights from /mnt/windows_drive_d/Amsterdam University/Year_1/FACT/embeddings/debiased_word2vec.bin\n",
      "05:01:10 INFO:Loading #26391 words with 300 dim\n",
      "05:01:11 INFO:Transformed 26391 into 26391 words\n",
      "05:01:11 INFO:Calculating similarity benchmarks\n",
      "05:01:11 WARNING:Missing 105 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on MTurk 0.5147397816605231\n",
      "05:01:11 WARNING:Missing 41 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on WS353 0.6469043976824834\n",
      "05:01:11 WARNING:Missing 1924 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on RW 0.2765561126719885\n",
      "05:01:11 WARNING:Missing 528 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on MEN 0.7038274693541311\n",
      "05:01:11 WARNING:Missing 17 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on SimLex999 0.4380078526648712\n",
      "05:01:11 WARNING:Missing 25 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on WS353S 0.7183759912504556\n",
      "05:01:11 WARNING:Missing 12 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on RG65 0.6940586411160337\n",
      "05:01:11 WARNING:Missing 23 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Spearman correlation of scores on WS353R 0.5782573884838683\n",
      "05:01:11 INFO:Calculating analogy benchmarks\n",
      "05:01:11 WARNING:Missing 2171 words. Will replace them with mean vector\n",
      "05:01:11 INFO:Processing 1/80 batch\n",
      "05:01:12 INFO:Processing 9/80 batch\n",
      "05:01:12 INFO:Processing 17/80 batch\n",
      "05:01:13 INFO:Processing 25/80 batch\n",
      "05:01:13 INFO:Processing 33/80 batch\n",
      "05:01:14 INFO:Processing 41/80 batch\n",
      "05:01:14 INFO:Processing 49/80 batch\n",
      "05:01:15 INFO:Processing 57/80 batch\n",
      "05:01:15 INFO:Processing 65/80 batch\n",
      "05:01:16 INFO:Processing 73/80 batch\n",
      "05:01:16 INFO:Analogy prediction accuracy on MSR 0.57\n",
      "05:01:16 WARNING:Missing 29945 words. Will replace them with mean vector\n",
      "05:01:16 INFO:Processing 1/196 batch\n",
      "05:01:18 INFO:Processing 20/196 batch\n",
      "05:01:19 INFO:Processing 39/196 batch\n",
      "05:01:20 INFO:Processing 58/196 batch\n",
      "05:01:21 INFO:Processing 77/196 batch\n",
      "05:01:23 INFO:Processing 96/196 batch\n",
      "05:01:24 INFO:Processing 115/196 batch\n",
      "05:01:25 INFO:Processing 134/196 batch\n",
      "05:01:26 INFO:Processing 153/196 batch\n",
      "05:01:27 INFO:Processing 172/196 batch\n",
      "05:01:29 INFO:Processing 191/196 batch\n",
      "05:01:29 INFO:Analogy prediction accuracy on Google 0.33202005730659023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "05:01:29 INFO:Analogy prediction accuracy on SemEval2012 0.20300340542239614\n",
      "05:01:29 INFO:Calculating categorization benchmarks\n",
      "05:01:29 DEBUG:Purity=0.750 using affinity=euclidean linkage=ward\n",
      "05:01:29 DEBUG:Purity=0.800 using affinity=cosine linkage=average\n",
      "05:01:29 DEBUG:Purity=0.450 using affinity=cosine linkage=complete\n",
      "05:01:29 DEBUG:Purity=0.800 using affinity=euclidean linkage=average\n",
      "05:01:29 DEBUG:Purity=0.450 using affinity=euclidean linkage=complete\n",
      "05:01:29 DEBUG:Purity=0.750 using KMeans\n",
      "05:01:29 INFO:Cluster purity on ESSLI_2b 0.8\n",
      "05:01:30 DEBUG:Purity=0.557 using affinity=euclidean linkage=ward\n",
      "05:01:30 DEBUG:Purity=0.356 using affinity=cosine linkage=average\n",
      "05:01:30 DEBUG:Purity=0.448 using affinity=cosine linkage=complete\n",
      "05:01:30 DEBUG:Purity=0.164 using affinity=euclidean linkage=average\n",
      "05:01:30 DEBUG:Purity=0.448 using affinity=euclidean linkage=complete\n",
      "05:01:30 DEBUG:Purity=0.418 using KMeans\n",
      "05:01:30 INFO:Cluster purity on AP 0.5572139303482587\n",
      "05:01:30 DEBUG:Purity=0.705 using affinity=euclidean linkage=ward\n",
      "05:01:30 DEBUG:Purity=0.727 using affinity=cosine linkage=average\n",
      "05:01:30 DEBUG:Purity=0.705 using affinity=cosine linkage=complete\n",
      "05:01:30 DEBUG:Purity=0.727 using affinity=euclidean linkage=average\n",
      "05:01:30 DEBUG:Purity=0.727 using affinity=euclidean linkage=complete\n",
      "05:01:30 DEBUG:Purity=0.773 using KMeans\n",
      "05:01:30 INFO:Cluster purity on ESSLI_1a 0.7727272727272727\n",
      "05:01:34 DEBUG:Purity=0.233 using affinity=euclidean linkage=ward\n",
      "05:01:37 DEBUG:Purity=0.114 using affinity=cosine linkage=average\n",
      "05:01:40 DEBUG:Purity=0.204 using affinity=cosine linkage=complete\n",
      "05:01:44 DEBUG:Purity=0.071 using affinity=euclidean linkage=average\n",
      "05:01:47 DEBUG:Purity=0.201 using affinity=euclidean linkage=complete\n",
      "05:01:51 DEBUG:Purity=0.230 using KMeans\n",
      "05:01:51 INFO:Cluster purity on Battig 0.23303383674249667\n",
      "05:01:51 DEBUG:Purity=0.680 using affinity=euclidean linkage=ward\n",
      "05:01:51 DEBUG:Purity=0.560 using affinity=cosine linkage=average\n",
      "05:01:51 DEBUG:Purity=0.615 using affinity=cosine linkage=complete\n",
      "05:01:51 DEBUG:Purity=0.385 using affinity=euclidean linkage=average\n",
      "05:01:51 DEBUG:Purity=0.615 using affinity=euclidean linkage=complete\n",
      "05:01:52 DEBUG:Purity=0.590 using KMeans\n",
      "05:01:52 INFO:Cluster purity on BLESS 0.68\n",
      "05:01:52 DEBUG:Purity=0.600 using affinity=euclidean linkage=ward\n",
      "05:01:52 DEBUG:Purity=0.511 using affinity=cosine linkage=average\n",
      "05:01:52 DEBUG:Purity=0.644 using affinity=cosine linkage=complete\n",
      "05:01:52 DEBUG:Purity=0.444 using affinity=euclidean linkage=average\n",
      "05:01:52 DEBUG:Purity=0.644 using affinity=euclidean linkage=complete\n",
      "05:01:52 DEBUG:Purity=0.667 using KMeans\n",
      "05:01:52 INFO:Cluster purity on ESSLI_2c 0.6666666666666667\n",
      "05:01:52 INFO:Saving results...\n",
      "         AP  BLESS    Battig      ...         Google   MSR  SemEval2012_2\n",
      "0  0.557214   0.68  0.233034      ...        0.33202  0.57       0.203003\n",
      "\n",
      "[1 rows x 17 columns]\n",
      "05:01:53 INFO:loading projection weights from /mnt/windows_drive_d/Amsterdam University/Year_1/FACT/embeddings/bias_glove.bin\n",
      "05:01:53 INFO:Loading #23177 words with 300 dim\n",
      "05:01:53 INFO:Transformed 23177 into 23177 words\n",
      "05:01:53 INFO:Calculating similarity benchmarks\n",
      "05:01:53 WARNING:Missing 232 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on MEN 0.7640203069954894\n",
      "05:01:53 WARNING:Missing 37 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on WS353 0.6976501269372408\n",
      "05:01:53 WARNING:Missing 20 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on WS353S 0.7656929744062716\n",
      "05:01:53 WARNING:Missing 4 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on RG65 0.7519751760203851\n",
      "05:01:53 WARNING:Missing 12 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on SimLex999 0.3984030932203347\n",
      "05:01:53 WARNING:Missing 1952 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on RW 0.17729003925442693\n",
      "05:01:53 WARNING:Missing 60 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on MTurk 0.6403831293505392\n",
      "05:01:53 WARNING:Missing 21 words. Will replace them with mean vector\n",
      "05:01:53 INFO:Spearman correlation of scores on WS353R 0.656220602117019\n",
      "05:01:53 INFO:Calculating analogy benchmarks\n",
      "05:01:54 WARNING:Missing 2723 words. Will replace them with mean vector\n",
      "05:01:54 INFO:Processing 1/80 batch\n",
      "05:01:54 INFO:Processing 9/80 batch\n",
      "05:01:55 INFO:Processing 17/80 batch\n",
      "05:01:55 INFO:Processing 25/80 batch\n",
      "05:01:55 INFO:Processing 33/80 batch\n",
      "05:01:56 INFO:Processing 41/80 batch\n",
      "05:01:56 INFO:Processing 49/80 batch\n",
      "05:01:57 INFO:Processing 57/80 batch\n",
      "05:01:57 INFO:Processing 65/80 batch\n",
      "05:01:58 INFO:Processing 73/80 batch\n",
      "05:01:58 INFO:Analogy prediction accuracy on MSR 0.550125\n",
      "05:01:59 WARNING:Missing 21265 words. Will replace them with mean vector\n",
      "05:01:59 INFO:Processing 1/196 batch\n",
      "05:02:00 INFO:Processing 20/196 batch\n",
      "05:02:01 INFO:Processing 39/196 batch\n",
      "05:02:02 INFO:Processing 58/196 batch\n",
      "05:02:03 INFO:Processing 77/196 batch\n",
      "05:02:04 INFO:Processing 96/196 batch\n",
      "05:02:05 INFO:Processing 115/196 batch\n",
      "05:02:06 INFO:Processing 134/196 batch\n",
      "05:02:07 INFO:Processing 153/196 batch\n",
      "05:02:09 INFO:Processing 172/196 batch\n",
      "05:02:10 INFO:Processing 191/196 batch\n",
      "05:02:10 INFO:Analogy prediction accuracy on Google 0.3861543184609087\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "05:02:10 INFO:Analogy prediction accuracy on SemEval2012 0.18305891125870358\n",
      "05:02:10 INFO:Calculating categorization benchmarks\n",
      "05:02:14 DEBUG:Purity=0.272 using affinity=euclidean linkage=ward\n",
      "05:02:18 DEBUG:Purity=0.163 using affinity=cosine linkage=average\n",
      "05:02:22 DEBUG:Purity=0.214 using affinity=cosine linkage=complete\n",
      "05:02:26 DEBUG:Purity=0.087 using affinity=euclidean linkage=average\n",
      "05:02:29 DEBUG:Purity=0.214 using affinity=euclidean linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.267 using KMeans\n",
      "05:02:34 INFO:Cluster purity on Battig 0.2720321162301663\n",
      "05:02:34 DEBUG:Purity=0.755 using affinity=euclidean linkage=ward\n",
      "05:02:34 DEBUG:Purity=0.605 using affinity=cosine linkage=average\n",
      "05:02:34 DEBUG:Purity=0.670 using affinity=cosine linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.600 using affinity=euclidean linkage=average\n",
      "05:02:34 DEBUG:Purity=0.660 using affinity=euclidean linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.705 using KMeans\n",
      "05:02:34 INFO:Cluster purity on BLESS 0.755\n",
      "05:02:34 DEBUG:Purity=0.750 using affinity=euclidean linkage=ward\n",
      "05:02:34 DEBUG:Purity=0.750 using affinity=cosine linkage=average\n",
      "05:02:34 DEBUG:Purity=0.750 using affinity=cosine linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.750 using affinity=euclidean linkage=average\n",
      "05:02:34 DEBUG:Purity=0.750 using affinity=euclidean linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.775 using KMeans\n",
      "05:02:34 INFO:Cluster purity on ESSLI_2b 0.775\n",
      "05:02:34 DEBUG:Purity=0.622 using affinity=euclidean linkage=ward\n",
      "05:02:34 DEBUG:Purity=0.533 using affinity=cosine linkage=average\n",
      "05:02:34 DEBUG:Purity=0.556 using affinity=cosine linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.533 using affinity=euclidean linkage=average\n",
      "05:02:34 DEBUG:Purity=0.556 using affinity=euclidean linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.556 using KMeans\n",
      "05:02:34 INFO:Cluster purity on ESSLI_2c 0.6222222222222222\n",
      "05:02:34 DEBUG:Purity=0.532 using affinity=euclidean linkage=ward\n",
      "05:02:34 DEBUG:Purity=0.311 using affinity=cosine linkage=average\n",
      "05:02:34 DEBUG:Purity=0.468 using affinity=cosine linkage=complete\n",
      "05:02:34 DEBUG:Purity=0.256 using affinity=euclidean linkage=average\n",
      "05:02:34 DEBUG:Purity=0.468 using affinity=euclidean linkage=complete\n",
      "05:02:35 DEBUG:Purity=0.480 using KMeans\n",
      "05:02:35 INFO:Cluster purity on AP 0.5323383084577115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:02:35 DEBUG:Purity=0.727 using affinity=euclidean linkage=ward\n",
      "05:02:35 DEBUG:Purity=0.614 using affinity=cosine linkage=average\n",
      "05:02:35 DEBUG:Purity=0.727 using affinity=cosine linkage=complete\n",
      "05:02:35 DEBUG:Purity=0.614 using affinity=euclidean linkage=average\n",
      "05:02:35 DEBUG:Purity=0.727 using affinity=euclidean linkage=complete\n",
      "05:02:35 DEBUG:Purity=0.727 using KMeans\n",
      "05:02:35 INFO:Cluster purity on ESSLI_1a 0.7272727272727273\n",
      "05:02:35 INFO:Saving results...\n",
      "         AP  BLESS    Battig      ...          Google       MSR  SemEval2012_2\n",
      "0  0.532338  0.755  0.272032      ...        0.386154  0.550125       0.183059\n",
      "\n",
      "[1 rows x 17 columns]\n",
      "05:02:36 INFO:loading projection weights from /mnt/windows_drive_d/Amsterdam University/Year_1/FACT/embeddings/debiased_glove.bin\n",
      "05:02:36 INFO:Loading #23177 words with 300 dim\n",
      "05:02:36 INFO:Transformed 23177 into 23177 words\n",
      "05:02:36 INFO:Calculating similarity benchmarks\n",
      "05:02:36 WARNING:Missing 12 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on SimLex999 0.4008367026997834\n",
      "05:02:36 WARNING:Missing 37 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on WS353 0.6972526340614563\n",
      "05:02:36 WARNING:Missing 21 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on WS353R 0.654641703491018\n",
      "05:02:36 WARNING:Missing 1952 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on RW 0.17895933922617063\n",
      "05:02:36 WARNING:Missing 232 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on MEN 0.7639824955047995\n",
      "05:02:36 WARNING:Missing 20 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on WS353S 0.7635325073658183\n",
      "05:02:36 WARNING:Missing 60 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on MTurk 0.6342419286839535\n",
      "05:02:36 WARNING:Missing 4 words. Will replace them with mean vector\n",
      "05:02:36 INFO:Spearman correlation of scores on RG65 0.7528493878679979\n",
      "05:02:36 INFO:Calculating analogy benchmarks\n",
      "05:02:37 WARNING:Missing 2723 words. Will replace them with mean vector\n",
      "05:02:37 INFO:Processing 1/80 batch\n",
      "05:02:37 INFO:Processing 9/80 batch\n",
      "05:02:38 INFO:Processing 17/80 batch\n",
      "05:02:38 INFO:Processing 25/80 batch\n",
      "05:02:39 INFO:Processing 33/80 batch\n",
      "05:02:39 INFO:Processing 41/80 batch\n",
      "05:02:40 INFO:Processing 49/80 batch\n",
      "05:02:40 INFO:Processing 57/80 batch\n",
      "05:02:41 INFO:Processing 65/80 batch\n",
      "05:02:41 INFO:Processing 73/80 batch\n",
      "05:02:42 INFO:Analogy prediction accuracy on MSR 0.551625\n",
      "05:02:42 WARNING:Missing 21265 words. Will replace them with mean vector\n",
      "05:02:42 INFO:Processing 1/196 batch\n",
      "05:02:43 INFO:Processing 20/196 batch\n",
      "05:02:44 INFO:Processing 39/196 batch\n",
      "05:02:45 INFO:Processing 58/196 batch\n",
      "05:02:46 INFO:Processing 77/196 batch\n",
      "05:02:47 INFO:Processing 96/196 batch\n",
      "05:02:48 INFO:Processing 115/196 batch\n",
      "05:02:49 INFO:Processing 134/196 batch\n",
      "05:02:50 INFO:Processing 153/196 batch\n",
      "05:02:51 INFO:Processing 172/196 batch\n",
      "05:02:52 INFO:Processing 191/196 batch\n",
      "05:02:53 INFO:Analogy prediction accuracy on Google 0.3841076545231273\n",
      "/home/yovchev/miniconda3/envs/test/lib/python3.5/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n",
      "05:02:53 INFO:Analogy prediction accuracy on SemEval2012 0.18448897715694\n",
      "05:02:53 INFO:Calculating categorization benchmarks\n",
      "05:02:53 DEBUG:Purity=0.542 using affinity=euclidean linkage=ward\n",
      "05:02:53 DEBUG:Purity=0.376 using affinity=cosine linkage=average\n",
      "05:02:53 DEBUG:Purity=0.483 using affinity=cosine linkage=complete\n",
      "05:02:53 DEBUG:Purity=0.259 using affinity=euclidean linkage=average\n",
      "05:02:53 DEBUG:Purity=0.483 using affinity=euclidean linkage=complete\n",
      "05:02:54 DEBUG:Purity=0.435 using KMeans\n",
      "05:02:54 INFO:Cluster purity on AP 0.5422885572139303\n",
      "05:02:54 DEBUG:Purity=0.760 using affinity=euclidean linkage=ward\n",
      "05:02:54 DEBUG:Purity=0.640 using affinity=cosine linkage=average\n",
      "05:02:54 DEBUG:Purity=0.670 using affinity=cosine linkage=complete\n",
      "05:02:54 DEBUG:Purity=0.600 using affinity=euclidean linkage=average\n",
      "05:02:54 DEBUG:Purity=0.660 using affinity=euclidean linkage=complete\n",
      "05:02:54 DEBUG:Purity=0.670 using KMeans\n",
      "05:02:54 INFO:Cluster purity on BLESS 0.76\n",
      "05:02:54 DEBUG:Purity=0.750 using affinity=euclidean linkage=ward\n",
      "05:02:54 DEBUG:Purity=0.750 using affinity=cosine linkage=average\n",
      "05:02:54 DEBUG:Purity=0.750 using affinity=cosine linkage=complete\n",
      "05:02:54 DEBUG:Purity=0.750 using affinity=euclidean linkage=average\n",
      "05:02:54 DEBUG:Purity=0.750 using affinity=euclidean linkage=complete\n",
      "05:02:54 DEBUG:Purity=0.725 using KMeans\n",
      "05:02:54 INFO:Cluster purity on ESSLI_2b 0.75\n",
      "05:02:58 DEBUG:Purity=0.268 using affinity=euclidean linkage=ward\n",
      "05:03:01 DEBUG:Purity=0.161 using affinity=cosine linkage=average\n",
      "05:03:05 DEBUG:Purity=0.222 using affinity=cosine linkage=complete\n",
      "05:03:08 DEBUG:Purity=0.084 using affinity=euclidean linkage=average\n",
      "05:03:12 DEBUG:Purity=0.222 using affinity=euclidean linkage=complete\n",
      "05:03:17 DEBUG:Purity=0.270 using KMeans\n",
      "05:03:17 INFO:Cluster purity on Battig 0.2695469317530109\n",
      "05:03:17 DEBUG:Purity=0.727 using affinity=euclidean linkage=ward\n",
      "05:03:17 DEBUG:Purity=0.614 using affinity=cosine linkage=average\n",
      "05:03:17 DEBUG:Purity=0.727 using affinity=cosine linkage=complete\n",
      "05:03:17 DEBUG:Purity=0.614 using affinity=euclidean linkage=average\n",
      "05:03:17 DEBUG:Purity=0.727 using affinity=euclidean linkage=complete\n",
      "05:03:17 DEBUG:Purity=0.818 using KMeans\n",
      "05:03:17 INFO:Cluster purity on ESSLI_1a 0.8181818181818182\n",
      "05:03:17 DEBUG:Purity=0.622 using affinity=euclidean linkage=ward\n",
      "05:03:17 DEBUG:Purity=0.533 using affinity=cosine linkage=average\n",
      "05:03:17 DEBUG:Purity=0.556 using affinity=cosine linkage=complete\n",
      "05:03:17 DEBUG:Purity=0.533 using affinity=euclidean linkage=average\n",
      "05:03:17 DEBUG:Purity=0.556 using affinity=euclidean linkage=complete\n",
      "05:03:17 DEBUG:Purity=0.556 using KMeans\n",
      "05:03:17 INFO:Cluster purity on ESSLI_2c 0.6222222222222222\n",
      "05:03:17 INFO:Saving results...\n",
      "         AP  BLESS    Battig      ...          Google       MSR  SemEval2012_2\n",
      "0  0.542289   0.76  0.269547      ...        0.384108  0.551625       0.184489\n",
      "\n",
      "[1 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "!cd code/benchmark/scripts/ && ./run_test.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
